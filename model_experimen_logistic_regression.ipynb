{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14242,"databundleVersionId":568274,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:56:26.567083Z","iopub.execute_input":"2025-04-27T18:56:26.567472Z","iopub.status.idle":"2025-04-27T18:56:26.992874Z","shell.execute_reply.started":"2025-04-27T18:56:26.567437Z","shell.execute_reply":"2025-04-27T18:56:26.991879Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/ieee-fraud-detection/sample_submission.csv\n/kaggle/input/ieee-fraud-detection/test_identity.csv\n/kaggle/input/ieee-fraud-detection/train_identity.csv\n/kaggle/input/ieee-fraud-detection/test_transaction.csv\n/kaggle/input/ieee-fraud-detection/train_transaction.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"pd.set_option('display.max_columns', None)  \npd.set_option('display.width', None)        \npd.set_option('display.expand_frame_repr', False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:56:28.948649Z","iopub.execute_input":"2025-04-27T18:56:28.950100Z","iopub.status.idle":"2025-04-27T18:56:28.955208Z","shell.execute_reply.started":"2025-04-27T18:56:28.950053Z","shell.execute_reply":"2025-04-27T18:56:28.954052Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_transaction.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:56:30.551573Z","iopub.execute_input":"2025-04-27T18:56:30.552120Z","iopub.status.idle":"2025-04-27T18:56:53.174883Z","shell.execute_reply.started":"2025-04-27T18:56:30.552090Z","shell.execute_reply":"2025-04-27T18:56:53.173794Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# DATA SPLIT","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nunique_cards = df['card1'].unique()\n\n\ncard_train, card_val_test = train_test_split(unique_cards, test_size=0.4, random_state=42)\ncard_val, card_test = train_test_split(card_val_test, test_size=0.5, random_state=42)\n\ntrain = df[df['card1'].isin(card_train)]\nval = df[df['card1'].isin(card_val)]\ntest = df[df['card1'].isin(card_test)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:57:02.284653Z","iopub.execute_input":"2025-04-27T18:57:02.285935Z","iopub.status.idle":"2025-04-27T18:57:03.991809Z","shell.execute_reply.started":"2025-04-27T18:57:02.285890Z","shell.execute_reply":"2025-04-27T18:57:03.990934Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"print(train['isFraud'].mean(), val['isFraud'].mean(), test['isFraud'].mean())\n\nprint(len(set(train['card1']) & set(val['card1'])))  \nprint(len(set(train['card1']) & set(test['card1']))) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:57:03.992923Z","iopub.execute_input":"2025-04-27T18:57:03.993271Z","iopub.status.idle":"2025-04-27T18:57:04.100797Z","shell.execute_reply.started":"2025-04-27T18:57:03.993250Z","shell.execute_reply":"2025-04-27T18:57:04.099846Z"}},"outputs":[{"name":"stdout","text":"0.03513108235162511 0.03890206572198909 0.03122020767664969\n0\n0\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"train_ids = train.pop('TransactionID')\ny_train = train.pop('isFraud')\nx_train = train\n\nval_ids = val.pop('TransactionID')\ny_val = val.pop('isFraud')\nx_val = val\n\ntest_ids = test.pop('TransactionID')\ny_test = test.pop('isFraud')\nx_test = test\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:57:07.115017Z","iopub.execute_input":"2025-04-27T18:57:07.115428Z","iopub.status.idle":"2025-04-27T18:57:07.126420Z","shell.execute_reply.started":"2025-04-27T18:57:07.115393Z","shell.execute_reply":"2025-04-27T18:57:07.125350Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# DATA CLEAN\n","metadata":{}},{"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\nclass SmartMissingHandler(BaseEstimator, TransformerMixin):\n    def __init__(self, nan_threshold=0.8, fraud_ratio_threshold=2.5, verbose=True):\n        self.nan_threshold = nan_threshold\n        self.fraud_ratio_threshold = fraud_ratio_threshold\n        self.verbose = verbose\n        self.high_risk_cols_ = None\n        self.cols_to_drop_ = None\n        self.mean_fraud_rate_ = None\n        \n    def _print(self, message):\n        if self.verbose:\n            print(message)\n            \n    def fit(self, X, y=None):\n        \"\"\"Identify high-risk columns and columns to drop\"\"\"\n        X = X.copy()\n        self._print(\"\\n=== Starting Fit ===\")\n        \n        nan_rates = X.isnull().mean()\n        self.cols_to_drop_ = nan_rates[nan_rates >= self.nan_threshold].index.tolist()\n        X = X.drop(columns=self.cols_to_drop_)\n        \n        if y is not None:\n            self.mean_fraud_rate_ = y.mean()\n            missing_analysis = []\n            \n            for col in X.columns:\n                if X[col].isnull().sum() > 0:\n                    fraud_missing = y[X[col].isnull()].mean()\n                    fraud_not_missing = y[~X[col].isnull()].mean()\n                    ratio = fraud_missing / max(fraud_not_missing, 1e-6)\n                    \n                    if ratio >= self.fraud_ratio_threshold:\n                        missing_analysis.append({\n                            'column': col,\n                            'fraud_ratio': ratio,\n                            'missing_rate': X[col].isnull().mean()\n                        })\n            \n            self.high_risk_cols_ = [x['column'] for x in \n                                  sorted(missing_analysis, \n                                  key=lambda x: -x['fraud_ratio'])]\n        \n        return self\n    \n    def transform(self, X):\n        \"\"\"Apply transformations without DataFrame fragmentation\"\"\"\n        X = X.copy()\n        \n        X = X.drop(columns=self.cols_to_drop_, errors='ignore')\n        \n        flag_data = {}\n        impute_data = {}\n        \n        for col in (self.high_risk_cols_ or []):\n            if col in X.columns:\n                flag_data[f'{col}_MISSING'] = X[col].isnull().astype(int)\n                if pd.api.types.is_numeric_dtype(X[col]):\n                    impute_data[col] = X[col].fillna(-999)\n                else:\n                    impute_data[col] = X[col].fillna('MISSING_CAT')\n        \n        other_cols = [c for c in X.columns \n                     if c not in (self.high_risk_cols_ or []) \n                     and X[c].isnull().any()]\n        \n        for col in other_cols:\n            mode_val = X[col].mode()[0] if not X[col].mode().empty else (0 if pd.api.types.is_numeric_dtype(X[col]) else 'MISSING')\n            impute_data[col] = X[col].fillna(mode_val)\n        \n        X = X.assign(**impute_data)\n        if flag_data:\n            X = pd.concat([X, pd.DataFrame(flag_data, index=X.index)], axis=1)\n        \n        return X","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:57:08.063759Z","iopub.execute_input":"2025-04-27T18:57:08.064697Z","iopub.status.idle":"2025-04-27T18:57:08.079405Z","shell.execute_reply.started":"2025-04-27T18:57:08.064657Z","shell.execute_reply":"2025-04-27T18:57:08.078378Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# FEATURE SELECTION","metadata":{}},{"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\nimport pandas as pd\nimport numpy as np\n\nclass CorrelationRemover(BaseEstimator, TransformerMixin):\n    def __init__(self, threshold=0.9, method='pearson', verbose=True):\n        self.threshold = threshold\n        self.method = method\n        self.verbose = verbose\n        self.cols_to_drop_ = []\n        \n    def fit(self, X, y=None):\n        X = pd.DataFrame(X).copy()\n        \n        num_cols = X.select_dtypes(include=np.number).columns\n        X_num = X[num_cols].replace([np.inf, -np.inf], np.nan)\n        \n        if X_num.isna().any().any():\n            raise ValueError(\"Found NA values in supposedly clean numeric data\")\n            \n        try:\n            corr_matrix = X_num.corr(method=self.method).abs()\n        except Exception as e:\n            print(f\"Correlation failed. Checking problematic columns...\")\n            problematic = []\n            for col in num_cols:\n                try:\n                    X_num[col].astype(float)\n                except:\n                    problematic.append(col)\n            raise ValueError(f\"Non-numeric values found in columns: {problematic}\")\n        \n        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n        self.cols_to_drop_ = [col for col in upper.columns \n                            if any(upper[col] >= self.threshold)]\n        \n        if self.verbose:\n            print(f\"Removing {len(self.cols_to_drop_)} features with {self.method} corr â‰¥ {self.threshold}\")\n        return self\n    \n    def transform(self, X):\n        return pd.DataFrame(X).drop(columns=self.cols_to_drop_, errors='ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T18:57:11.142022Z","iopub.execute_input":"2025-04-27T18:57:11.142409Z","iopub.status.idle":"2025-04-27T18:57:11.152857Z","shell.execute_reply.started":"2025-04-27T18:57:11.142382Z","shell.execute_reply":"2025-04-27T18:57:11.151616Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"!pip install -U scikit-learn==1.3.2 imbalanced-learn==0.11.0","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# TRAINING","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import PredefinedSplit, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom imblearn.pipeline import Pipeline as ImbPipeline\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom category_encoders import TargetEncoder\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score, RocCurveDisplay, classification_report\nimport matplotlib.pyplot as plt\n\n\ncategorical_cols = [col for col in x_train.columns if x_train[col].dtype == 'object']\nnumerical_cols = [col for col in x_train.columns if x_train[col].dtype != 'object']\n\ncategorical_cols = x_train.select_dtypes(include=['object'])\nfiltered_cats = [col for col in categorical_cols.columns\n                 if df[col].isnull().mean() < 0.8]\n\nencoder = TargetEncoder(\n    cols=filtered_cats, \n    smoothing=10.0 \n)\n\nmissing_handler = SmartMissingHandler(\n    nan_threshold=0.85,          \n    fraud_ratio_threshold=2    \n)\n\nparam_grid = {\n    'clf__C': [0.01, 0.1]\n}\n\nX_full = pd.concat([x_train, x_val], axis=0)\ny_full = pd.concat([y_train, y_val], axis=0)\nsplit_index = [-1] * len(x_train) + [0] * len(x_val)\nps = PredefinedSplit(test_fold=split_index)\n\n\n\nfull_pipeline = ImbPipeline([\n    ('missing', missing_handler),\n    ('encoder', encoder),\n    ('scaler', StandardScaler()),\n    ('selector', VarianceThreshold(threshold=0.01)),\n    ('correlation_remover', CorrelationRemover(threshold=0.95)),\n    ('undersample', RandomUnderSampler(random_state=42)),\n    ('clf', LogisticRegression(max_iter=1000, solver='liblinear', random_state=42))\n])\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nnum_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='most_frequent'))\n])\n\ncat_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('encoder', TargetEncoder(smoothing=10.0))\n])\n\npreprocessor = ColumnTransformer([\n    ('num', num_pipeline, numerical_cols),\n    ('cat', cat_pipeline, categorical_cols)\n])\n\nfull_pipeline = ImbPipeline([\n    ('preprocess', preprocessor),\n    ('scaler', StandardScaler()),\n    ('selector', VarianceThreshold(threshold=0.01)),\n    ('correlation_remover', CorrelationRemover(threshold=0.95)),\n    ('undersample', RandomUnderSampler(random_state=42)),\n    ('clf', LogisticRegression(max_iter=1000, solver='liblinear', random_state=42))\n])\n\nparam_grid = {\n    'clf__C': [0.1, 1]\n}\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"grid = GridSearchCV(\n    estimator=full_pipeline,\n    param_grid=param_grid,\n    cv=ps,\n    scoring='roc_auc',\n    n_jobs=-1,\n    verbose=3,\n    error_score='raise'\n)\n\ngrid.fit(X_full, y_full)\n\nbest_model = grid.best_estimator_\nprint(f\"Best params: {grid.best_params_}\")\nprint(f\"Validation roc-auc: {grid.best_score_:.4f}\")\n\ny_train_proba = best_model.predict_proba(x_train)[:, 1]\ntrain_roc_auc = roc_auc_score(y_train, y_train_proba)\n\n\ny_test_proba = best_model.predict_proba(x_test)[:, 1]\ntest_roc_auc = roc_auc_score(y_test, y_test_proba)\n\nprint(f\"Train ROC-AUC: {train_roc_auc:.4f}\")\n\nprint(f\"Test ROC-AUC: {test_roc_auc:.4f}\")\n\n\ny_test_pred = (y_test_proba > 0.5).astype(int)\n\n\nprint(classification_report(y_test, y_test_pred))\n\nRocCurveDisplay.from_predictions(y_test, y_test_proba)\nplt.title(\"Test ROC Curve\")\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# MLFLOW LOGGING","metadata":{}},{"cell_type":"code","source":"!pip install mlflow dagshub","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import dagshub\ndagshub.init(repo_owner='abarb22', repo_name='IEEE-fraud-detection', mlflow=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import mlflow\nfrom sklearn.metrics import roc_auc_score, classification_report, RocCurveDisplay, precision_score, recall_score, f1_score\nimport mlflow.sklearn\nimport os\nimport matplotlib.pyplot as plt\n\n\n\nmlflow.set_experiment(\"LogisticRegression_Training\")\n\nwith mlflow.start_run(run_name=\"LogReg_Trial_2\") as parent_run:\n    with mlflow.start_run(run_name=\"Preprocessing\", nested=True):\n        mlflow.log_param(\"numerical_columns\", numerical_cols)\n        mlflow.log_param(\"categorical_columns\", categorical_cols)\n\n        \n        # Log TargetEncoder parameter\n        mlflow.log_param(\"target_encoder_smoothing\", 10.0)\n        mlflow.log_metric(\"n_missing_train\", x_train.isnull().sum().sum())\n\n    with mlflow.start_run(run_name=\"LR_FeatureSelection\", nested=True):\n        mlflow.log_param(\"variance_threshold\", 0.01)\n        mlflow.log_param(\"correlation_threshold\", 0.95)\n\n    with mlflow.start_run(run_name=\"LR_CV_Training\",  nested=True):\n        # Log search space and best hyperparameters\n        mlflow.log_params({f\"grid__{k}\": v for k, v in param_grid.items()})\n        mlflow.log_param(\"model\", \"LogisticRegression\")\n        mlflow.log_param(\"solver\", \"liblinear\")\n        mlflow.log_param(\"max_iter\", 1000)\n        mlflow.log_param(\"cv_type\", \"PredefinedSplit\")\n        mlflow.log_param(\"undersampling\", \"RandomUnderSampler\")\n        mlflow.log_param(\"C_values_grid\", param_grid['clf__C'])\n        mlflow.log_metric(\"val_roc_auc\", grid.best_score_)\n        mlflow.log_param(\"best_C\", grid.best_params_)\n \n\n    with mlflow.start_run(run_name=\"LR_FinalModel\" , nested=True):\n        mlflow.log_metric(\"train_roc_auc\", train_roc_auc)\n        mlflow.log_metric(\"test_roc_auc\", test_roc_auc)\n        mlflow.log_metric(\"val_roc_auc\", grid.best_score_)\n    \n        y_test_pred = (y_test_proba > 0.5).astype(int)\n        mlflow.log_metric(\"test_precision\", precision_score(y_test, y_test_pred))\n        mlflow.log_metric(\"test_recall\", recall_score(y_test, y_test_pred))\n        mlflow.log_metric(\"test_f1\", f1_score(y_test, y_test_pred))\n\n        # Log classification report as text\n        report = classification_report(y_test, y_test_pred)\n        mlflow.log_text(report, \"classification_report.txt\")\n\n        # Log model\n        mlflow.sklearn.log_model(best_model, \"final_model\")\n\n        # Log ROC curve plot\n        RocCurveDisplay.from_predictions(y_test, y_test_proba)\n        plt.title(\"Test ROC Curve\")\n        plt.grid(True)\n        plt.savefig(\"roc_curve.png\")\n        mlflow.log_artifact(\"roc_curve.png\")\n        \n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}